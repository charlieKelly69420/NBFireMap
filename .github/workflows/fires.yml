name: Fetch NB Fire Feeds

on:
  schedule:
    - cron: "38 * * * *"
  workflow_dispatch:
permissions:
  contents: write

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Ensure jq is available
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y jq
          fi

      - name: Fetch and verify feeds (10-in-a-row, up to 5 passes, 2s per copy, 30s between passes)
        id: fetch
        env:
          BASE: https://gis-erd-der.gnb.ca/arcgis/rest/services/Fire_Dashboards/Public_Fires/MapServer
          # GeoJSON for GitHub map (WGS84)
          QUERY_GEO: '?where=1%3D1&outFields=*&outSR=4326&f=geojson'
          # Esri Feature JSON (for consumers that need aliases/fields)
          QUERY_JSON: '?where=1%3D1&outFields=*&f=json'
          TABLE_NAME: SDEOWNER.V_FIRE_DASHBOARD_SUM
          COPIES: "10"
        run: |
          set -euo pipefail

          cleanup_prefix() {
            rm -f "${1}"[0-9][0-9].json "${1}"[0-9][0-9].geojson || true
          }

          download_n() {
            local url="$1" prefix="$2" n="${3:-10}"
            cleanup_prefix "$prefix"
            for i in $(seq -w 01 "$n"); do
              tmpfile="$(mktemp)"
              if ! curl -sS --fail --retry 3 --retry-delay 2 --retry-connrefused --max-time 60 "$url" -o "$tmpfile"; then
                echo "Curl failed for ${url}"
                rm -f "$tmpfile"
                return 1
              fi
              if ! jq -e type "$tmpfile" >/dev/null 2>&1; then
                echo "Invalid JSON for ${url}"
                rm -f "$tmpfile"
                return 1
              fi
              # Keep the extension from the given prefix (e.g., .geojson or .json)
              local base="${prefix%.*}"
              local ext="${prefix##*.}"
              mv "$tmpfile" "${base}${i}.${ext}"
              sleep 2
            done
          }

          all_match() {
            local prefix="$1"
            ls ${prefix%.*}[0-9][0-9].* >/dev/null 2>&1 || return 1
            local uniq_count
            uniq_count=$(sha256sum ${prefix%.*}[0-9][0-9].* | awk '{print $1}' | sort | uniq | wc -l | tr -d ' ')
            test "$uniq_count" -eq 1
          }

          get_table_id() {
            local meta
            if ! meta="$(curl -sS --fail "$BASE?f=pjson")"; then
              echo "Failed to read service metadata"; return 1
            fi
            echo "$meta" | jq -e --arg NAME "$TABLE_NAME" '.tables[] | select(.name==$NAME) | .id' 2>/dev/null | tr -d '\r\n'
          }

          # Adds UPDATED_FROM_ERD at the root (fieldAliases + fields) for Esri JSON,
          # and into each feature (attributes for Esri / properties for GeoJSON).
          write_with_timestamp() {
            local src="$1" dest="$2"
            local ts; ts="$(date -u +'%Y-%m-%dT%H:%M:%SZ')"

            jq --arg ts "$ts" '
              def add_field_meta:
                .fieldAliases = ((.fieldAliases // {}) + {"UPDATED_FROM_ERD":"UPDATED_FROM_ERD"}) |
                .fields = (
                  (.fields // [])
                  | ( if (map(.name) | index("UPDATED_FROM_ERD")) then .
                      else . + [{
                        "name":"UPDATED_FROM_ERD",
                        "type":"esriFieldTypeString",
                        "alias":"UPDATED_FROM_ERD",
                        "sqlType":"sqlTypeNVarchar",
                        "length":20,
                        "nullable":true,
                        "editable":true,
                        "domain":null,
                        "defaultValue":null
                      }]
                    end )
                );

              if .type=="FeatureCollection" and (.features|type)=="array" then
                # GeoJSON: just set the property on each feature
                .features |= map(.properties |= ((. // {}) + {"UPDATED_FROM_ERD": $ts}))
              elif (.features|type)=="array" then
                # Esri Feature JSON: add root field metadata + per-feature attribute
                add_field_meta |
                .features |= map(.attributes |= ((. // {}) + {"UPDATED_FROM_ERD": $ts}))
              else
                # Some ArcGIS table/feature responses are just { features:[...] } without .type
                if (.features|type)=="array" and (.features[0]? .attributes? != null) then
                  add_field_meta |
                  .features |= map(.attributes |= ((. // {}) + {"UPDATED_FROM_ERD": $ts}))
                else
                  .
                end
              end
            ' "$src" > "${dest}.tmp"
            mv "${dest}.tmp" "$dest"
          }

          ACTIVE_NEEDED=true
          OUT_NEEDED=true
          TABLE_NEEDED=true

          TID="$(get_table_id || true)"
          if [ -z "${TID:-}" ]; then
            echo "Could not find table id for $TABLE_NAME in service metadata."
            TABLE_NEEDED=false
          fi

          ANY_CHANGED=false

          for pass in 1 2 3 4 5; do
            echo "::group::Pass $pass"

            # --- LAYER 0: Active fires ---
            if [ "$ACTIVE_NEEDED" = true ]; then
              echo "Attempt: active fires (layer 0) -> GeoJSON"
              if download_n "$BASE/0/query$QUERY_GEO" "active_fires.geojson" "$COPIES"; then
                if all_match "active_fires.geojson"; then
                  write_with_timestamp active_fires01.geojson active_fires.geojson
                  echo "Active fires GeoJSON stabilized on pass $pass"
                else
                  echo "Active fires GeoJSON NOT stable on pass $pass."
                fi
              else
                echo "Active fires GeoJSON download failed on pass $pass."
              fi
              cleanup_prefix "active_fires.geojson"

              echo "Attempt: active fires (layer 0) -> Esri JSON (with aliases/fields)"
              if download_n "$BASE/0/query$QUERY_JSON" "active_fires_esri.json" "$COPIES"; then
                if all_match "active_fires_esri.json"; then
                  write_with_timestamp active_fires_esri01.json active_fires_esri.json
                  echo "Active fires Esri JSON stabilized on pass $pass"
                  ACTIVE_NEEDED=false
                  ANY_CHANGED=true
                else
                  echo "Active fires Esri JSON NOT stable on pass $pass."
                fi
              else
                echo "Active fires Esri JSON download failed on pass $pass."
              fi
              cleanup_prefix "active_fires_esri.json"
            fi

            # --- LAYER 1: Out fires ---
            if [ "$OUT_NEEDED" = true ]; then
              echo "Attempt: out fires (layer 1) -> GeoJSON"
              if download_n "$BASE/1/query$QUERY_GEO" "out_fires.geojson" "$COPIES"; then
                if all_match "out_fires.geojson"; then
                  write_with_timestamp out_fires01.geojson out_fires.geojson
                  echo "Out fires GeoJSON stabilized on pass $pass"
                else
                  echo "Out fires GeoJSON NOT stable on pass $pass."
                fi
              else
                echo "Out fires GeoJSON download failed on pass $pass."
              fi
              cleanup_prefix "out_fires.geojson"

              echo "Attempt: out fires (layer 1) -> Esri JSON (with aliases/fields)"
              if download_n "$BASE/1/query$QUERY_JSON" "out_fires_esri.json" "$COPIES"; then
                if all_match "out_fires_esri.json"; then
                  write_with_timestamp out_fires_esri01.json out_fires_esri.json
                  echo "Out fires Esri JSON stabilized on pass $pass"
                  OUT_NEEDED=false
                  ANY_CHANGED=true
                else
                  echo "Out fires Esri JSON NOT stable on pass $pass."
                fi
              else
                echo "Out fires Esri JSON download failed on pass $pass."
              fi
              cleanup_prefix "out_fires_esri.json"
            fi

            # --- TABLE (non-spatial summary) ---
            if [ "$TABLE_NEEDED" = true ]; then
              echo "Attempt: table $TABLE_NAME (id=${TID:-unknown}) -> Esri JSON (with aliases/fields)"
              if [ -n "${TID:-}" ]; then
                if download_n "$BASE/$TID/query$QUERY_JSON" "v_fire_dashboard_sum.json" "$COPIES"; then
                  if all_match "v_fire_dashboard_sum.json"; then
                    write_with_timestamp v_fire_dashboard_sum01.json v_fire_dashboard_sum.json
                    echo "Table $TABLE_NAME stabilized on pass $pass"
                    TABLE_NEEDED=false
                    ANY_CHANGED=true
                  else
                    echo "Table $TABLE_NAME NOT stable on pass $pass."
                  fi
                else
                  echo "Table $TABLE_NAME download failed on pass $pass."
                fi
                cleanup_prefix "v_fire_dashboard_sum.json"
              else
                echo "Skipping table; no table id."
              fi
            fi

            echo "::endgroup::"

            if [ "$ACTIVE_NEEDED" = false ] && [ "$OUT_NEEDED" = false ] && [ "$TABLE_NEEDED" = false ]; then
              break
            else
              echo "Some datasets still unstable; waiting 30s before next pass..."
              sleep 30
            fi
          done

          echo "any_changed=$ANY_CHANGED" >> "$GITHUB_OUTPUT"

      - name: Commit updated data (only what changed)
        if: steps.fetch.outputs.any_changed == 'true'
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add active_fires.geojson out_fires.geojson \
                 active_fires_esri.json out_fires_esri.json \
                 v_fire_dashboard_sum.json || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            ts="$(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git commit -m "Update fire feeds (${ts})"
            git push
          fi
